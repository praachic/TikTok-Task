{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "994fb763-42ba-4de6-894b-4833baad5665",
   "metadata": {},
   "source": [
    "# TikTok data and LLM coding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6059f03e-0e53-4749-9243-41360d093091",
   "metadata": {},
   "source": [
    "### Setup \n",
    "\n",
    "Run the following cells to set up this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc12003f-5c4b-445b-8153-17ae3709152c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from IPython.display import display, clear_output\n",
    "import json\n",
    "from ipywidgets import widgets, VBox, HBox, Button, Label, Output\n",
    "import krippendorff\n",
    "import pandas as pd\n",
    "import pyktok as pyk\n",
    "import random\n",
    "from openai import OpenAI\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2903e1f-82f2-490d-9299-9eb568e1d422",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39120900-3ea9-45c9-bd62-fb9acd4dab3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d27d00-2de1-4633-8c23-51a81acc270b",
   "metadata": {},
   "source": [
    "## Exploring Public Opinion in TikTok Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45c3f9b-88a1-4301-b11f-46b63e7ca028",
   "metadata": {},
   "source": [
    "This week we will be exploring TikTok's role in shaping public opinion. Social media has become a popular site of discourse, and platforms like TikTok have been credited for shaping popular culture, politics, and everyday interactions. TikTok comment sections are a site where public opinion is debated and negotiated. At the same time, platform-level decisions alter what comments are most visible on comment pages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f51d31-b4cd-4e68-9c9a-5666082563f6",
   "metadata": {},
   "source": [
    "## Choosing a Debate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62795eb6-39c7-4309-997f-10692b0d9b99",
   "metadata": {},
   "source": [
    "Create a group of 2 (where at least one person in the group has a TikTok account) and find a video related to popular culture that has discusses two clearly defined positions as a part of a greater debate. This video should also have at least 10k comments. Copy the url of the video and paste it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1609ded6-6c47-4b43-8761-4f761c0780ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your video URL\n",
    "video_url = \"https://www.tiktok.com/@abcnews/video/7413187084074159391\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f9e8f0-ae12-4c0c-84b7-b1a3aae819e5",
   "metadata": {},
   "source": [
    "## Scrape Comments!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd0bd5e-2bdf-4d21-88f4-8c40b454cd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_comments():\n",
    "    pyk.save_tiktok_comments(video_url,\n",
    "                         comment_count=1000,\n",
    "                         save_comments=True,\n",
    "                         return_comments=False,)\n",
    "\n",
    "await get_comments()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768c25aa-3f99-424b-877d-761f6f02c511",
   "metadata": {},
   "source": [
    "## Define a Research Question\n",
    "What are you hoping to learn by studying comments on this video?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc6b317-84e9-4f9f-8d8d-872e5182aec7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f0fec6a-7d63-45b7-8955-2ba4663edf08",
   "metadata": {},
   "source": [
    "## Defining Concepts\n",
    "Quantitative content analysis is a popular method for translating non-numeric content into numeric, quantitative data. To do so, researchers create clearly defined and validated concepts. The first step in studying our TikTok debate is clearly defining how each position should be coded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08359cfa-eaac-4bad-ac3b-1f18b89de1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept1 = \"\"\n",
    "\n",
    "concept2 = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c652e5f-c6ab-4a9a-9b25-4d5c9cc2d080",
   "metadata": {},
   "source": [
    "## Let's Code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e6852a-eba7-4356-9673-473dd05344f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!Replace with your filename!!\n",
    "df = pd.read_csv('@abcnews_video_7413187084074159391_comments.csv') \n",
    "\n",
    "sample_df = df.sample(n=100, random_state=42).reset_index(drop=True)\n",
    "text_col = 'text'\n",
    "\n",
    "for col in ['coder1_concept1', 'coder1_concept2', 'coder2_concept1', 'coder2_concept2']:\n",
    "    sample_df[col] = None\n",
    "\n",
    "main_out = Output()\n",
    "coder1_out = Output()\n",
    "coder2_out = Output()\n",
    "\n",
    "def code_entries(coder_label, concept1_col, concept2_col, container_out, next_callback=None):\n",
    "    index = 0\n",
    "    text_label = Label(value=sample_df.loc[index, text_col])\n",
    "\n",
    "    # !!Change the descriptions to your concepts!!\n",
    "    concept1 = widgets.ToggleButtons(options=[0, 1], description='Concept 1:')\n",
    "    concept2 = widgets.ToggleButtons(options=[0, 1], description='Concept 2:')\n",
    "    \n",
    "    next_button = Button(description='Next â†’', button_style='success')\n",
    "    progress = Label(value=f\"{coder_label}: {index + 1}/{len(sample_df)}\")\n",
    "\n",
    "    def next_entry(_):\n",
    "        nonlocal index\n",
    "        sample_df.loc[index, concept1_col] = concept1.value\n",
    "        sample_df.loc[index, concept2_col] = concept2.value\n",
    "\n",
    "        index += 1\n",
    "        if index < len(sample_df):\n",
    "            text_label.value = sample_df.loc[index, text_col]\n",
    "            concept1.value = None\n",
    "            concept2.value = None\n",
    "            progress.value = f\"{coder_label}: {index + 1}/{len(sample_df)}\"\n",
    "        else:\n",
    "            container_out.clear_output()\n",
    "            with container_out:\n",
    "                display(Label(value=f\"{coder_label} has finished coding! âœ…\"))\n",
    "                if next_callback:\n",
    "                    next_callback()\n",
    "                else:\n",
    "                    with main_out:\n",
    "                        print(\"âœ… Both coders finished. Saving data...\")\n",
    "                        sample_df.to_csv('coded_data.csv', index=False)\n",
    "                        print(\"ðŸ’¾ Coded data saved to coded_data.csv\")\n",
    "\n",
    "    next_button.on_click(next_entry)\n",
    "\n",
    "    with container_out:\n",
    "        container_out.clear_output()\n",
    "        display(VBox([progress, text_label, concept1, concept2, next_button]))\n",
    "\n",
    "# ---- Workflow ----\n",
    "\n",
    "def start_coder2():\n",
    "    print(\"\\n=== Coder 2: Please start coding ===\")\n",
    "    code_entries(\"Coder 2\", \"coder2_concept1\", \"coder2_concept2\", coder2_out)\n",
    "\n",
    "print(f\"Concept 1: {concept1}\")\n",
    "print(f\"Concept 2: {concept2}\\n\")\n",
    "\n",
    "print(\"=== Coder 1: Please start coding ===\")\n",
    "code_entries(\"Coder 1\", \"coder1_concept1\", \"coder1_concept2\", coder1_out, next_callback=start_coder2)\n",
    "\n",
    "display(coder1_out, coder2_out, main_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd11a885-2c32-4b1c-b7b9-9c8625e9dfb6",
   "metadata": {},
   "source": [
    "## Assess Interrater Reliability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8421ef63-7b12-4116-a271-49d922990c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"coded_data.csv\")\n",
    "\n",
    "def krippendorff_alpha_for_concept(df, concept_name):\n",
    "    data = [\n",
    "        df[f'coder1_{concept_name}'].tolist(),\n",
    "        df[f'coder2_{concept_name}'].tolist()\n",
    "    ]\n",
    "    return krippendorff.alpha(reliability_data=data, level_of_measurement='nominal')\n",
    "\n",
    "alpha_concept1 = krippendorff_alpha_for_concept(df, \"concept1\")\n",
    "alpha_concept2 = krippendorff_alpha_for_concept(df, \"concept2\")\n",
    "\n",
    "print(\"Krippendorffâ€™s Alpha Scores:\")\n",
    "print(f\"â€¢ Concept 1: {alpha_concept1:.3f}\")\n",
    "print(f\"â€¢ Concept 2: {alpha_concept2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797fb1b4-f58c-4e86-9e31-6ccc7aa5f7dc",
   "metadata": {},
   "source": [
    "## Evaluate the interrater reliability and iterate!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24ff85e6-77d3-4c4f-9063-74bce49be6bc",
   "metadata": {},
   "source": [
    "![](krippendorff.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cb422f-e50a-466d-878b-02fb43492b70",
   "metadata": {},
   "source": [
    "Describe your interrater reliability. If you scored high, great! How did your concept descriptions help you code effectively? If you scored poorly, what might you have done better?\n",
    "\n",
    "**Regardless of your score, discuss potential edge cases and improve your concept descriptions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb86b6a-e942-482f-a132-9da8effd2f69",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75173a8c-0583-43f3-8ec2-3b311aabe408",
   "metadata": {},
   "source": [
    "## Hire a LLM coder!\n",
    "Write a prompt for an LLM to code the same 100 comments and calculate intercoder reliability. Be sure to tell the LLM their role!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22762f31-4477-42e5-93f3-ee526621d1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_prompt = '''You are a research assistant. \n",
    "                You will receive a series of tiktok comments, \n",
    "                please code for if the comment supports Kamala Harris or Donald trump.\n",
    "             '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38ded76-dffd-4971-b443-bc68852927df",
   "metadata": {},
   "source": [
    "## Code with your LLM coder!\n",
    "For the human coding, agree on a code with your partner for each of the concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68035b02-9258-4c6f-a146-e510d1e139dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_col = \"text\"\n",
    "\n",
    "sample_df[\"human_concept1\"] = None\n",
    "sample_df[\"human_concept2\"] = None\n",
    "\n",
    "def code_entries():\n",
    "    index = 0\n",
    "    out = Output()\n",
    "\n",
    "    text_label = widgets.Textarea(value=sample_df.loc[index, text_col], layout=widgets.Layout(width='600px', height='120px'))\n",
    "    concept1 = widgets.ToggleButtons(options=[0, 1], description=\"Concept 1:\")\n",
    "    concept2 = widgets.ToggleButtons(options=[0, 1], description=\"Concept 2:\")\n",
    "    next_button = Button(description=\"Next â†’\", button_style=\"success\")\n",
    "    progress = Label(value=f\"Human Coding: {index + 1}/{len(sample_df)}\")\n",
    "\n",
    "    def next_entry(_):\n",
    "        nonlocal index\n",
    "        sample_df.loc[index, \"human_concept1\"] = concept1.value\n",
    "        sample_df.loc[index, \"human_concept2\"] = concept2.value\n",
    "\n",
    "        index += 1\n",
    "        if index < len(sample_df):\n",
    "            text_label.value = sample_df.loc[index, text_col]\n",
    "            concept1.value = None\n",
    "            concept2.value = None\n",
    "            progress.value = f\"Human Coding: {index + 1}/{len(sample_df)}\"\n",
    "        else:\n",
    "            clear_output()\n",
    "            display(Label(value=\"âœ… Human coding complete! Now AI will code the same sample.\"))\n",
    "            out.clear_output()\n",
    "\n",
    "    next_button.on_click(next_entry)\n",
    "    display(VBox([progress, text_label, concept1, concept2, next_button, out]))\n",
    "\n",
    "code_entries()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d0e9e7-0103-4e06-b431-bfb6fa02c111",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "\n",
    "def ai_code_batch(text_list):\n",
    "    texts_formatted = \"\\n\".join([f\"{i+1}. {t}\" for i, t in enumerate(text_list)])\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "        {LLM_prompt}\n",
    "        \n",
    "        You will receive {len(text_list)} texts.\n",
    "        \n",
    "        Return ONLY valid JSON â€” a list of {len(text_list)} dictionaries like this:\n",
    "        \n",
    "        [\n",
    "          {{\"concept1\": 1, \"concept2\": 0}},\n",
    "          ...\n",
    "        ]\n",
    "        \n",
    "        No explanations, no comments, no extra text â€” only the JSON array.\n",
    "        \n",
    "        Texts:\n",
    "        {texts_formatted}\n",
    "        \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        output_text = response.choices[0].message.content.strip()\n",
    "        batch_json = json.loads(output_text)\n",
    "        return batch_json  \n",
    "    except Exception as e:\n",
    "        try:\n",
    "            print(\"Trying to parse\")\n",
    "            s = string.replace(\"```\", \"\").replace(\"json\", \"\").replace(\"\\n\", \"\").strip()\n",
    "            lst = json.loads(s)\n",
    "            print(\"âœ… Parsed successfully.\")\n",
    "            return lst\n",
    "        except Exception as e:\n",
    "            print(\"âš ï¸ Parsing error:\", e)\n",
    "\n",
    "            return [{\"concept1\": None, \"concept2\": None} for _ in text_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5722b66-87f0-4e5f-8baa-9c8d8dd6bdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ai_concept1, sample_ai_concept2 = [], []\n",
    "\n",
    "for start in range(0, len(sample_df), batch_size):\n",
    "    print(f\"Beginning coding round {batch_size/10}\")\n",
    "    end = start + batch_size\n",
    "    sample_batch_texts = sample_df[text_col].iloc[start:end].tolist()\n",
    "    sample_batch_results = ai_code_batch(sample_batch_texts)\n",
    "\n",
    "    for r in sample_batch_results:\n",
    "        sample_ai_concept1.append(r.get(\"concept1\"))\n",
    "        sample_ai_concept2.append(r.get(\"concept2\"))\n",
    "\n",
    "sample_df[\"ai_concept1\"] = sample_ai_concept1\n",
    "sample_df[\"ai_concept2\"] = sample_ai_concept2\n",
    "\n",
    "sample_df.to_csv(\"ai_coded_data.csv\", index=False)\n",
    "print(\"âœ… Combined human + AI coded data saved to ai_coded_data.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc4032c-203e-4b8c-bef6-a571a1876959",
   "metadata": {},
   "source": [
    "## Evaluate your agreement\n",
    "Repeat the process until you reach at least 0.7 agreeability with the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d5bb4e-7e31-4089-8fcb-2acddf85cd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def krippendorff_alpha_for_concept(df, concept_name):\n",
    "    data = [\n",
    "        df[f\"human_{concept_name}\"].tolist(),\n",
    "        df[f\"ai_{concept_name}\"].tolist()\n",
    "    ]\n",
    "    return krippendorff.alpha(reliability_data=data, level_of_measurement='nominal')\n",
    "\n",
    "alpha_c1 = krippendorff_alpha_for_concept(sample_df, \"concept1\")\n",
    "alpha_c2 = krippendorff_alpha_for_concept(sample_df, \"concept2\")\n",
    "\n",
    "print(\"Krippendorffâ€™s Alpha between Human and AI:\")\n",
    "print(f\"â€¢ Concept 1: {alpha_c1:.3f}\")\n",
    "print(f\"â€¢ Concept 2: {alpha_c2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c061373-5bfb-40c2-b809-7faaf94765c0",
   "metadata": {},
   "source": [
    "## Use your prompt to code the entire comments dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbbe05d-2c05-4be9-8f04-80045a56f256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! Change file name !!\n",
    "comments = pd.read_csv(\"@abcnews_video_7413187084074159391_comments.csv\")\n",
    "comments = comments.head(100)\n",
    "\n",
    "ai_concept1, ai_concept2 = [], []\n",
    "\n",
    "for start in range(0, len(comments), batch_size):\n",
    "    print(f\"Beginning coding round {(start/10) + 1}\")\n",
    "    end = start + batch_size\n",
    "    batch_texts = comments[text_col].iloc[start:end].tolist()\n",
    "    batch_results = ai_code_batch(batch_texts)\n",
    "\n",
    "    for r in batch_results:\n",
    "        ai_concept1.append(r.get(\"concept1\"))\n",
    "        ai_concept2.append(r.get(\"concept2\"))\n",
    "\n",
    "# Add results to dataframe\n",
    "comments[\"ai_concept1\"] = ai_concept1\n",
    "comments[\"ai_concept2\"] = ai_concept2\n",
    "\n",
    "# Save to file\n",
    "comments.to_csv(\"final_coded_data.csv\", index=False)\n",
    "print(\"âœ… Finished Coding!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6c563f-5992-4391-858f-db19449aec15",
   "metadata": {},
   "source": [
    "## Analyze your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27ec181-6070-404a-8dbf-c180bd512a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_coded_data = pd.read_csv(\"final_coded_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac33c35-ca50-482e-9333-a01df6e121db",
   "metadata": {},
   "source": [
    "#### Exploring quantity of comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27a7376-8ffe-4cf1-a3b3-48983955d857",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = {\n",
    "    \"ai_concept1\": final_coded_data[\"ai_concept1\"].sum(),\n",
    "    \"ai_concept2\": final_coded_data[\"ai_concept2\"].sum()\n",
    "}\n",
    "\n",
    "count_df = pd.DataFrame(list(counts.items()), columns=[\"Concept\", \"Total_1s\"])\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(count_df[\"Concept\"], count_df[\"Total_1s\"])\n",
    "plt.title(\"Total Count of 1s by AI Concept\")\n",
    "plt.ylabel(\"Count of 1s\")\n",
    "plt.xlabel(\"Concept\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6964c80c-1152-45dc-97c1-db0e06d54f89",
   "metadata": {},
   "source": [
    "#### What comments received more likes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355ac419-cc3f-405f-8375-cb5c611df000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapse(x):\n",
    "    if x.ai_concept1 == 1:\n",
    "        return \"concept1\"\n",
    "    elif x.ai_concept2 == 1:\n",
    "        return \"concept2\"\n",
    "    else:\n",
    "        return \"neither\"\n",
    "\n",
    "final_coded_data['collapsed_codes'] = final_coded_data.apply(collapse, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceca90a-9c0d-48da-9d18-44bfca0cfb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=final_coded_data, y='collapsed_codes', x='digg_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0323f35-1333-484a-a921-282c7018b45e",
   "metadata": {},
   "source": [
    "#### What comments got the most replies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b582f321-9c08-4cc2-9b6d-ced3deb46228",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=final_coded_data, y='collapsed_codes', x='reply_comment_total')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf30aca-9310-4098-b597-6cb2b16058ab",
   "metadata": {},
   "source": [
    "#### What types of comments are shown more?\n",
    "This is a visibility metric: higher scores means higher visibility in the comment section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5796f349-6347-4f88-872e-9869c19eb237",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_coded_data['sort_extra_score_loaded'] = final_coded_data.sort_extra_score.apply(lambda x: ast.literal_eval(x))\n",
    "final_coded_data['show_more'] = final_coded_data.sort_extra_score_loaded.apply(lambda x: float(dict(x)['show_more_score']))\n",
    "sns.barplot(data=final_coded_data, y='collapsed_codes', x='show_more')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156fb191-ac3d-4c92-ac16-5163e8f3a637",
   "metadata": {},
   "source": [
    "#### Are there differences in age between commenters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b895a8-3ee7-4c3f-afae-5f1dc1e89d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_coded_data['users_loaded'] = final_coded_data.user.apply(lambda x: ast.literal_eval(x))\n",
    "final_coded_data['age'] = final_coded_data.users_loaded.apply(\n",
    "    lambda x: x['predicted_age_group'] if isinstance(x, dict) and 'predicted_age_group' in x else None\n",
    ")\n",
    "\n",
    "def reduce(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return float('nan')\n",
    "final_coded_data['age'] = final_coded_data.age.apply(reduce)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da44c2b3-0b10-49d1-8a0f-29186dc47d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=final_coded_data.dropna(subset='age'), y='collapsed_codes', x='age')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748c878d-995c-41b9-92ca-dacad16f8262",
   "metadata": {},
   "source": [
    "- group -1 = 13-17\n",
    "- group 1 = 18-24\n",
    "- group 2 = 25-34\n",
    "- group 3 = 35-44\n",
    "- group 4 = 45-54\n",
    "- group 5 = 55+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970b52af-0bd7-4908-b40c-3df55218b9a0",
   "metadata": {},
   "source": [
    "#### Use an LLM to create one more visualization or analysis\n",
    "You might need to inspect your data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f153bb-4910-424e-ba3b-a3898a38050d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cce4863b-5bc5-491b-b74b-992b1a614991",
   "metadata": {},
   "source": [
    "## What does it all mean??\n",
    "Spend 2-3 paragraphs reflecting on the results from your analysis. What are the implications of this work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da9a21a-ab02-4960-aa70-91ea0eca28b0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
